{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8b34d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solveurs directs\n",
    "\n",
    "Les solveurs directs reposent sur l'observation que trois types de\n",
    "matrices sont simples à inverser : les matrices diagonales, les matrices\n",
    "triangulaires (par descente ou remontée), les matrices unitaires (il\n",
    "suffit de les transposer). Pour les matrices plus compliquées, on\n",
    "cherche à se ramener à une combinaison multiplicative des cas\n",
    "précédents. On parle de factorisation.\n",
    "\n",
    "On considère le système\n",
    "${\\mathbf{A}}{\\mathbf{x}}={\\mathbf{b}}$\n",
    "dans $\\mathbb{E}^n$.\n",
    "\n",
    "## Systèmes triangulaires\n",
    "\n",
    "Les matrices triangulaires supérieures ou inférieures inversibles\n",
    "forment un groupe pour la multiplication. La résolution d'un système\n",
    "triangulaire est très simple (par descente ou remontée) et de complexité\n",
    "$O(n^2)$. Remarquons dès à présent qu'il est possible de travailler\n",
    "simultanément sur un ensemble de seconds membres (matrice rectangulaire\n",
    "avec relativement peu de colonnes, aussi appelée multivecteur). Le\n",
    "calcul du déterminant d'une matrice triangulaire est trivial (produit\n",
    "des coefficients diagonaux)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622e686",
   "metadata": {},
   "source": [
    "# Direct Solvers\n",
    "\n",
    "Direct solvers are based on the observation that three types of\n",
    "matrices are easy to invert: diagonal matrices, triangular matrices (by descent or\n",
    "triangular matrices (by descent or ascent), unitary matrices (it is enough to\n",
    "transpose them). For the more complicated matrices, we try to\n",
    "try to reduce to a multiplicative combination of the previous cases.\n",
    "previous cases. This is called factorization.\n",
    "\n",
    "We consider the system\n",
    "${\\mathbf{A}}{\\mathbf{x}}={\\mathbf{b}}$\n",
    "in $\\mathbb{E}^n$.\n",
    "\n",
    "## Triangular systems\n",
    "\n",
    "Invertible upper or lower triangular matrices\n",
    "form a group for multiplication. The solution of a triangular system\n",
    "triangular system is very simple (by descent or ascent) and of complexity\n",
    "$O(n^2)$. Let us note now that it is possible to work\n",
    "simultaneously on a set of second members (rectangular matrix\n",
    "with relatively few columns, also called multivector). The\n",
    "determinant of a triangular matrix is trivial (product of\n",
    "of the diagonal coefficients).\n",
    "\n",
    "Translated with www.DeepL.com/Translator (free version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b5110",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Concernant les problèmes de précision, on introduit le nombre\n",
    "$\\gamma_n = n\\times u/(1-n\\times u)$ (on rappelle que $u$ est l'erreur d'arrondi) qui est très proche de $n\\times u$ sauf si la taille du\n",
    "système devient colossale. On note $|{\\mathbf{A}}|$ la\n",
    "matrice obtenue en appliquant la valeur absolue (le module) à chacune\n",
    "des composante de ${\\mathbf{A}}$.\n",
    "\n",
    "On peut contrôler l'erreur rétrograde sous la forme\n",
    "$|\\Delta{\\mathbf{A}}|\\leqslant \\gamma_n |{\\mathbf{A}}|$.\n",
    "\n",
    "Concernant l'erreur directe, on a :\n",
    "$$||\\Delta x||_\\infty/  \\|x\\|_\\infty \\leqslant \\operatorname{cond}(T,x)\\gamma_n /(1-\\kappa_\\infty(T) \\gamma_n)$$\n",
    "où\n",
    "$\\operatorname{cond}(T,x)= \\frac{\\||T^{-1}|\\,|T|\\,|x|\\|_\\infty}{\\|x\\|_\\infty}\\leqslant\\kappa_\\infty(T)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66d3ab",
   "metadata": {},
   "source": [
    "Concerning the precision problems, we introduce the number\n",
    "$gamma_n = ntimes u/(1-ntimes u)$ (recall that $u$ is the rounding error) which is very close to $ntimes u$ unless the size of the system\n",
    "system becomes colossal. We note $|{{mathbf{A}}|$ the\n",
    "matrix obtained by applying the absolute value (the modulus) to each\n",
    "of the components of ${{mathbf{A}}}$.\n",
    "\n",
    "We can control the backward error in the form\n",
    "$|Delta{\\mathbf{A}}|leqslant \\gamma_n |{\\mathbf{A}}|$.\n",
    "\n",
    "Concerning the direct error, we have:\n",
    "$$||Delta x||_\\infty/ \\|x||_\\infty \\leqslant \\operatorname{cond}(T,x)\\gamma_n /(1-\\kappa_\\infty(T) \\gamma_n)$$\n",
    "where\n",
    "$$operatorname{cond}(T,x)=$frac{||T^{-1}||,|T||,|x||_\\infty}{\\x\\|_\\infty}{\\leqslant\\kappa_\\infty(T)$.\n",
    "\n",
    "\n",
    "Translated with www.DeepL.com/Translator (free version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85934926",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Méthode de Gauss et méthodes dérivées\n",
    "\n",
    "### Gauss\n",
    "\n",
    "Le principe de la méthode de Gauss est de trouver\n",
    "${\\mathbf{M}}$ triangulaire telle que\n",
    "${\\mathbf{M}}{\\mathbf{A}}{\\mathbf{x}}={\\mathbf{U}}{\\mathbf{x}}={\\mathbf{M}}{\\mathbf{b}}$\n",
    "avec ${\\mathbf{U}}$ triangulaire supérieure. C'est une\n",
    "méthode extrêmement générale, elle fait intervenir deux types de matrices.\n",
    "\n",
    "    \n",
    "-   matrices de permutation de ligne :\n",
    "\n",
    "$${\\mathbf{T}}_{i,j} = \\begin{pmatrix}\n",
    " 1 & & & & & & \\\\ \n",
    " & 1 & & & & &\\\\\n",
    " & & 0_{ii} & \\cdots & \\cdots & 1_{ij} & \\\\\n",
    " & & \\vdots & 1 & & \\vdots & \\\\\n",
    " & & \\vdots & & 1 & \\vdots & \\\\\n",
    " & & 1_{ji} &\\cdots&\\cdots& 0_{jj} & \\\\\n",
    " & & & & & & 1\n",
    " \\end{pmatrix}$$\n",
    "        \n",
    "Ces matrices ont un déterminant de $(-1)$. Par convention on pose ${\\mathbf{T}}_{i,i}={\\mathbf{I}}$ dont le déterminant est 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2c5b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "-   matrices d'élimination de colonne :\n",
    "\n",
    "$$\\text{si } {\\mathbf{A}}=\n",
    "        \\begin{pmatrix}\n",
    "        a_{11} & a_{12} &        &  \\cdots    &        & a_{n1}  \\\\ \n",
    "        0      & \\ddots &        &            &        & \\vdots  \\\\\n",
    "        & \\ddots & \\ddots &            &        & \\vdots  \\\\\n",
    "        \\vdots &        & 0      & a_{jj}     & \\cdots & a_{jn}  \\\\\n",
    "        &        & \\vdots & \\vdots     &        & \\vdots  \\\\\n",
    "        0     &        & 0      & a_{nj}     & \\cdots & a_{nn} \n",
    "        \\end{pmatrix} \\qquad\n",
    "        \\text{avec }a_{jj}\\neq 0$$\n",
    "        \n",
    "$$\\text{on pose }\\gamma_{ij} = -a_{ij}/a_{jj} \n",
    "        \\qquad\n",
    "        \\text{ soit } {\\mathbf{E}}_j = \\begin{pmatrix}\n",
    "        1      &    0     &  \\cdots    &        & &0 \\\\ \n",
    "        0      &  \\ddots  &  \\ddots  &        & &  \\\\\n",
    "        \\vdots &   0     &  1_{jj}    &        &  & \\\\\n",
    "        &  \\vdots & \\gamma_{(j+1)j} & \\ddots &  & \\\\\n",
    "        &   \\vdots & \\vdots         &    0    & \\ddots& 0\\\\\n",
    "        0     &    0    & \\gamma_{nj} &    0    &  0    &1 \n",
    "        \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15f6d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Alors ${\\mathbf{E}}_j {\\mathbf{A}}$ est une\n",
    "matrice dont on a recombiné les lignes $(j+1)$ à $n$ pour faire\n",
    "disparaître les coefficients inférieurs de la colonne $j$. Les matrices\n",
    "${\\mathbf{E}}_j$ ont un déterminant de $1$. En itérant on\n",
    "construit :\n",
    "$${\\mathbf{M}}={\\mathbf{E}}_{n-1}{\\mathbf{T}}_{n-1}\\cdots{\\mathbf{E}}_{2}{\\mathbf{T}}_{2}{\\mathbf{E}}_{1}{\\mathbf{T}}_{1}, \\ \\text{et alors }  {\\mathbf{M}}{\\mathbf{A}} = {\\mathbf{U}}$$\n",
    "Le rôle des matrices de permutation est de s'assurer que le pivot\n",
    "$a_{ii}$ est non nul. Si tous ces coefficients sont nuls la matrice\n",
    "n'est pas inversible (on verra plus loin comment obtenir alors une base\n",
    "du noyau et une pseudo-inverse). Comme la matrice\n",
    "${\\mathbf{M}}$ a un déterminant de $\\pm 1$ (suivant la parité\n",
    "du nombre de pivotement), on a très simplement le déterminant de\n",
    "${\\mathbf{A}}$ égal au signe près à celui de\n",
    "${\\mathbf{U}}$.\n",
    "\n",
    "Numériquement, il est conseillé de toujours prendre le plus grand\n",
    "coefficient disponible comme pivot. On distingue les stratégies de pivot\n",
    "partiel où l'on va chercher le coefficient sur la colonne $j$ (ligne $j$\n",
    "à $n$) et les stratégies de pivot total où l'on va aussi chercher parmi\n",
    "les coefficients sur la ligne $j$ (colonne $j$ à $n$). Le pivot total\n",
    "revient à s'autoriser à multiplier la matrice à droite ce qui\n",
    "complexifie légèrement la méthode (surtout sa mise en œuvre)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb194ff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Pour calculer complètement l'inverse, on peut utiliser la transformation\n",
    "de Gauss-Jordan :\n",
    "$$\\text{ soit } {\\mathbf{\\hat{E}}}_j = \\begin{pmatrix}\n",
    "1      &       & 0 & \\gamma_{1j}    &    0    & &0 \\\\ \n",
    "0      &  \\ddots & & \\vdots       &        & & \\\\ \n",
    "&  \\ddots & \\ddots &  \\gamma_{(j-1)j}  &        & &  \\\\\n",
    "\\vdots &         & 0&  1_{jj}    &   0     &  & \\\\\n",
    "&  &\\vdots & \\gamma_{(j+1)j} & \\ddots &  & \\\\\n",
    "&   &\\vdots & \\vdots         &    0    & \\ddots& 0\\\\\n",
    "0     &        & 0& \\gamma_{nj} &    0    &  0    &1 \n",
    "\\end{pmatrix}$$ qui élimine entièrement la colonne $j$ (sauf le terme\n",
    "diagonal).\n",
    "\n",
    "La méthode du pivot de Gauss a une complexité en $O(n^3)$ sans compter\n",
    "la recherche des pivots qui n'est pas une opération de calcul mais une\n",
    "succession de conditions (qui ne correspondent pas au même type\n",
    "d'optimisations matérielles et logicielles).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cca92",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut comparer cette méthode à la méthode de Cramer qui donne la solution d'un système sous forme de quotients de déterminants. Pour appliquer la méthode de Cramer, il faut effectuer le calcul de $det(A)$, puis les calculs successifs de :\n",
    "\n",
    "$x_{1}=det(bA_{2}\\ldots A_{n})/det(A)$ avec $A_{i}$ la $i^{eme}$ colonne de la matrice $A$. \n",
    "\n",
    "$x_{2}=det(A_{1}bA_{3}\\ldots A_{n})/det(A)$\n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "$x_{n}=det(A_{1}A_{1}\\ldots A_{n-1}b)/det(A)$\n",
    "\n",
    "Essayons d'estimer le temps de calcul associé à cette résolution. Le nombre d'opérations nécessaires pour le calcul d'un déterminant est donné par la formule suivante : $det(A)=\\sum_{k=1}^{n} (-1)^{k}\\prod_{i=1}^{n} a_{i,k(i)} \\qquad \\mbox{$k$ : nombre de permutations}$\n",
    "\n",
    "On obtient donc $(n-1)n!$ multiplications et $n!-1$ additions. Le nombre d'opérations est donc de l'ordre de grandeur de $(n+1)!$. En évaluant la valeur de $n!$ par la formule de Stirling ($n!\\sim n^{n+1/2}e^{-n}\\sqrt{2\\pi}$), pour un système de dimension 100x100, on obtient $\\sim$10$^{160}$ opérations à effectuer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b4f59",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Le plus puissant supercalculateur en novembre 2022 est le Frontier - HPE Cray EX235a de l'Oak Ridge National Laboratory dans le Tenessee aux USA avec 8 730 112 cœurs. Il possède une puissance de calcul de 1102 Exaflop/s (le seul calculateur exaflopique : 1.102 Exaflop/s), soit un peu plus de $10^{21}$ opérations par seconde. Sachant qu'une année comprend $3.10^{7}$ s on obtient pour un système $100\\times100$ un temps de calcul de $10^{132}$ années soit $10^{120}$ fois l'âge de l'univers !!! Alors qu'avec une méthode adéquate le même calcul peut prendre moins d'une seconde. Pour la méthode de Gauss, il faut seulement $\\sim10^{6}$ opérations (et ce n'est pas la plus efficace).\n",
    "\n",
    "On propose de programmer la mathode de Gauss, on cherchera le plus grand pivot uniquement sur les colonnes de la matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb60025",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "\n",
    "n=100\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n",
    "# b est le second membre\n",
    "b = np.random.random((n,1))\n",
    "\n",
    "x1 = la.solve(A,b.flatten())\n",
    "\n",
    "def gauss_elimination(A, b):\n",
    "    n = len(A)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Find pivot\n",
    "        max_row = i\n",
    "        for j in range(i + 1, n):\n",
    "            if abs(A[j][i]) > abs(A[max_row][i]):\n",
    "                max_row = j\n",
    "\n",
    "        # Swap rows\n",
    "        A[i], A[max_row] = A[max_row], A[i]\n",
    "        b[i], b[max_row] = b[max_row], b[i]\n",
    "\n",
    "        # Eliminate\n",
    "        for j in range(i + 1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            b[j] -= factor * b[i]\n",
    "            for k in range(n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "\n",
    "    # Back substitution\n",
    "    x = [0 for _ in range(n)]\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x[i] = b[i]\n",
    "        for j in range(i + 1, n):\n",
    "            x[i] -= A[i][j] * x[j]\n",
    "        x[i] /= A[i][i]\n",
    "    return x\n",
    "\n",
    "\n",
    "res = gauss_elimination(A,b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f021b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Factorisation LU\n",
    "\n",
    "Dans certains cas, il est possible de ne pas pivoter et d'obtenir\n",
    "directement ${\\mathbf{M}}^{-1}={\\mathbf{L}}$, on a\n",
    "alors la factorisation\n",
    "${\\mathbf{A}}={\\mathbf{L}}{\\mathbf{U}}$\n",
    "de la matrice (pour que la factorisation soit unique, on impose que la\n",
    "matrice ${\\mathbf{L}}$ soit à diagonale unitaire). La\n",
    "condition de non-nécessité de pivotement est que tous les\n",
    "sous-déterminants soient non-nuls.\n",
    "\n",
    "La condition ne garantit pas que les pivots naturels soient les\n",
    "meilleurs (les plus gros des coefficients disponibles), et il est plus\n",
    "prudent de pivoter malgré tout. Les matrices à diagonale dominante font\n",
    "exceptions puisque leurs pivots naturels sont automatiquement les plus\n",
    "gros coefficients disponibles.\n",
    "\n",
    "Dans le cas tridiagonal, le calcul est particulièrement simple et la\n",
    "complexité devient de l'ordre de $n$. Les systèmes rectangulaires à\n",
    "sous-déterminants non-nuls peuvent aussi être factorisés sous forme LU\n",
    "($\\mathbf{L}$ ou $\\mathbf{U}$ est de la même forme que $\\mathbf{A}$\n",
    "tandis que l'autre matrice est carrée).\n",
    "\n",
    "Une variante de la factorisation LU est la factorisation LDU où\n",
    "$\\mathbf{L}$ est triangulaire inférieur à diagonale unitaire,\n",
    "${\\mathbf{D}}$ est diagonale et ${\\mathbf{U}}$\n",
    "triangulaire supérieure à diagonale unitaire. Une telle variante permet\n",
    "de mettre en exergue les éléments diagonaux (qui doivent être inversés\n",
    "lors d'une résolution) pour traiter un éventuel problème mal posé.\n",
    "\n",
    "Concernant la précision de la factorisation, on a le résultat suivant\n",
    "sur l'erreur rétrograde :\n",
    "$|\\Delta {\\mathbf{A}}|  \\leqslant \\gamma_{3n}/(1-\\gamma_n) |{\\mathbf{A}}|$.\n",
    "\n",
    "On propose d'implémenter le calcul d'une décomposition LU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c35f8642",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L same: True\n",
      "R same: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as lina\n",
    "\n",
    "n=50\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n",
    "\n",
    "P, L1, U1 = lina.lu(A)\n",
    "\n",
    "def lu_decomposition(A):\n",
    "    n = len(A)\n",
    "    L = np.eye(n)\n",
    "    U = A.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            L[j][i] = U[j][i]/U[i][i]\n",
    "            U[:][j] = U[:][j] - L[j][i]*U[:][i]\n",
    "            \n",
    "    return L, U\n",
    "\n",
    "\n",
    "L2, U2 = lu_decomposition(A)\n",
    "\n",
    "print(\"L same:\", np.allclose(L1, L2, 1e-6))\n",
    "print(\"R same:\", np.allclose(U1, U2, 1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16e381",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Factorisation de Crout\n",
    "\n",
    "Si la matrice est LU-factorisable et qu'elle est symétrique, elle\n",
    "peut-être factorisée sous la forme de Crout :\n",
    "${\\mathbf{A}}={\\mathbf{L}}{\\mathbf{D}}{\\mathbf{L}}^T$\n",
    "avec ${\\mathbf{D}}$ diagonale et ${\\mathbf{L}}$\n",
    "triangulaire inférieure à diagonale unitaire. Il est toujours recommandé\n",
    "de pivoter pour diminuer les erreurs d'arrondi, dans ce cas là il est\n",
    "nécessaire d'utiliser un pivot symétrique (multiplication à gauche par\n",
    "${\\mathbf{T}}_{ij}$ et à droite par\n",
    "${\\mathbf{T}}_{ij}^T={\\mathbf{T}}_{ij}$).\n",
    "\n",
    "### Factorisation de Cholesky\n",
    "\n",
    "Si la matrice est symétrique définie positive alors elle peut être\n",
    "factorisée sous la forme\n",
    "${\\mathbf{A}}={\\mathbf{L}}{\\mathbf{L}}^T$.\n",
    "On rappelle au passage qu'une matrice SPD a tous ses sous-déterminants\n",
    "strictement positifs.\n",
    "\n",
    "Le nombre d'opérations est approximativement deux fois plus petit que\n",
    "pour une factorisation LU.\n",
    "\n",
    "La factorisation de Cholesky a déjà été implémentée dans le chapitre 1. On en redonne pour mémoire un code ci-dessous.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eef16e8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 50\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38cd1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Orthogonalisation QR\n",
    "\n",
    "Dans le cas d'une matrice carrée, la factorisation QR permet d'écrire\n",
    "une matrice ${\\mathbf{A}}$ sous la forme du produit d'un\n",
    "matrice unitaire ${\\mathbf{Q}}$ et d'une matrice triangulaire\n",
    "supérieure ${\\mathbf{R}}$.\n",
    "\n",
    "Dans le cas d'une matrice rectangulaire on peut au choix obtenir\n",
    "${\\mathbf{Q}}$ unitaire $m\\times m$ et\n",
    "${\\mathbf{R}}$ triangulaire supérieure $m\\times n$ ou alors\n",
    "${\\mathbf{Q}}$ $m\\times n$ avec des colonnes (si $m>n$) ou\n",
    "des lignes (si $m<n$) orthonormales entre elles et\n",
    "${\\mathbf{R}}$ triangulaire supérieure $n\\times n$. Une\n",
    "application typique de cette factorisation est donc le calcul du rang\n",
    "d'une famille de vecteurs. On verra également qu'elle permet la\n",
    "résolution de problèmes au sens des moindres carrés. Pour les\n",
    "illustrations à venir on supposera la matrice carrée ou rectangulaire\n",
    "avec $n>m$ (cas assez récurent de la manipulation d'un petit paquet de\n",
    "très grands vecteurs).\n",
    "\n",
    "On peut fournir plusieurs théorèmes d'orthogonalisation. On donne\n",
    "celui-ci : si ${\\mathbf{A}}$ est une matrice carrée d'ordre\n",
    "$n$, il existe une matrice unitaire ${\\mathbf{Q}}$ et une\n",
    "matrice triangulaire ${\\mathbf{R}}$ telles que\n",
    "${\\mathbf{A}}={\\mathbf{Q}}{\\mathbf{R}}$.\n",
    "On peut de plus s'arranger pour que tous les éléments diagonaux de\n",
    "${\\mathbf{R}}$ soient positifs (ou nuls). Si\n",
    "${\\mathbf{A}}$ est inversible, la factorisation est alors\n",
    "unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d2033",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Version Gram-Schmidt\n",
    "\n",
    "L'orthogonalisation la plus simple est celle de Gram-Schmidt, elle\n",
    "consiste à enchainer les manipulations de colonnes de la matrice. On\n",
    "pose et $r_{11}=\\|{\\mathbf{a}}_1\\|_2$ et\n",
    "${\\mathbf{q}}_1={\\mathbf{a}}_1/r_{11}$, si on\n",
    "suppose avoir construit les $k$ premières colonnes de\n",
    "${\\mathbf{Q}}$ et le bloc $k\\times k$ de\n",
    "${\\mathbf{R}}$ tels que $$\\begin{pmatrix} \n",
    "\\vdots & \\vdots& \\vdots \\\\\n",
    "{\\mathbf{a}}_1, &\\vdots  & {\\mathbf{a}}_k \\\\\n",
    "\\vdots &\\vdots & \\vdots \n",
    "\\end{pmatrix}=\\begin{pmatrix} \n",
    "\\vdots & \\vdots& \\vdots \\\\\n",
    "{\\mathbf{q}}_1, &\\vdots  & {\\mathbf{q}}_k \\\\\n",
    "\\vdots &\\vdots & \\vdots \n",
    "\\end{pmatrix} \\begin{pmatrix}\n",
    "r_{11} & \\cdots & r_{1k} \\\\\n",
    "0 & \\ddots & \\vdots \\\\\n",
    "0 & 0 & r_{kk}\n",
    "\\end{pmatrix} \\qquad \\text{avec } {\\mathbf{q}}_i^H  {\\mathbf{q}}_j = \\delta_{ij}$$\n",
    "on calcule : $$\\begin{aligned}\n",
    "&\\text{pour }i=1\\cdots k\\quad r_{i(k+1)} = {\\mathbf{q}}_i^H {\\mathbf{a}}_{k+1} \\\\ \n",
    "&{\\mathbf{q}}_{k+1} = {\\mathbf{a}}_{k+1} - \\sum_i r_{i(k+1)}{\\mathbf{q}}_i \\\\\n",
    "& r_{(k+1)(k+1)} = \\|{\\mathbf{q}}_{k+1}\\|\\\\\n",
    "&{\\mathbf{q}}_{k+1} \\leftarrow  {\\mathbf{q}}_{k+1} / r_{(k+1)(k+1)} \n",
    "\\end{aligned}$$ L'algorithme présenté ici est dit de Gram-Schmidt\n",
    "classique, il peut s'écrire avantageusement sous forme de produits de\n",
    "sous-blocs de matrice et est donc facilement optimisable (du point de\n",
    "vue exécution sur un ordinateur). Par contre l'algorithme n'est pas\n",
    "stable. Si ${\\mathbf{Q}}$ et ${\\mathbf{R}}$ sont\n",
    "les matrices obtenues, on a\n",
    "$\\|{\\mathbf{A}}-{\\mathbf{Q}}{\\mathbf{R}}\\|$\n",
    "petit, mais\n",
    "$\\|{\\mathbf{Q}}^T{\\mathbf{Q}}-{\\mathbf{I}}\\|$\n",
    "devient rapidement grand, autrement dit on perd l'orthogonalité. Cela\n",
    "pose problème si l'on veut se servir de la factorisation pour résoudre\n",
    "un système\n",
    "\n",
    "Pour résoudre ce problème, on peut utilisée l'algorithme de Gram-Schmidt\n",
    "modifié, beaucoup plus stable (en fait très proche de Householder\n",
    "présenté plus bas) mais beaucoup plus coûteux : $$\\begin{aligned}\n",
    "& {\\mathbf{q}}_{k+1} = {\\mathbf{a}}_{k+1}\\\\\n",
    "&\\text{pour }i=1..(k+1)\\quad r_{i(k+1)} = {\\mathbf{q}}_i ^H {\\mathbf{q}}_{k+1}, \\quad {\\mathbf{q}}_{k+1} \\leftarrow {\\mathbf{q}}_{k+1}-  r_{i(k+1)}{\\mathbf{q}}_i \\\\\n",
    "& r_{(k+1)(k+1)} = \\|{\\mathbf{q}}_{k+1}\\|\\\\\n",
    "&{\\mathbf{q}}_{k+1}  \\leftarrow {\\mathbf{q}}_{k+1} / r_{(k+1)(k+1)}\n",
    "\\end{aligned}$$ Même améliorée, la méthode de Gram-Schmidt est simple à\n",
    "coder, à optimiser et surtout permet d'accéder à\n",
    "${\\mathbf{Q}}$ (si seul ${\\mathbf{R}}$ est\n",
    "recherché Householder est plus rapide).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21ab5be6",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9972901   0.05245861  0.05158058]\n",
      " [-0.05429321  0.99791727  0.03483332]\n",
      " [-0.04964585 -0.0375394   0.99806116]]\n",
      "[[3.8279314  0.41179134 0.36220533]\n",
      " [0.         3.8654458  0.25094528]\n",
      " [0.         0.         3.02446696]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 3\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n",
    "\n",
    "def modified_gram(A):\n",
    "    n = A.shape[0]\n",
    "    r = np.eye(n)\n",
    "    q = np.zeros((n,n))\n",
    "    v = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        v[:][i] = A[:][i]\n",
    "    for i in range(n):\n",
    "        r[i][i] = la.norm(v[:][i],2)\n",
    "        q[:][i] = v[:][i]/r[i][i]\n",
    "        for j in range(i+1, n):\n",
    "            r[i][j] = q[:][i]@v[:][j]\n",
    "            v[:][j] = v[:][j] - r[i][j]*q[:][i]\n",
    "\n",
    "    return q,r\n",
    "\n",
    "q,r = modified_gram(A)\n",
    "print(q)\n",
    "print(r)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d09e6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98441421  0.17549506  0.0114085 ]\n",
      " [ 0.1991429   0.96843955  0.14988975]\n",
      " [-0.03619378  0.13868754  0.98967458]]\n",
      "[[3.52565988 0.         0.15701557]\n",
      " [0.         3.10699446 0.        ]\n",
      " [0.         0.         3.15926839]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 3\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n",
    "\n",
    "def modified_gram(A):\n",
    "    n = A.shape[0]\n",
    "    r = np.eye(n)\n",
    "    q = np.zeros((n,n))\n",
    "    v = np.zeros((n,n))\n",
    "    for k in range(n):\n",
    "        q[k] = A[k]\n",
    "        for i in range(k-1):\n",
    "            r[i][k] = q[i].T@q[k]\n",
    "            q[k] = q[k] - r[i][k]*q[i]\n",
    "        r[k][k] = la.norm(q[k],2)\n",
    "        q[k] = q[k]/r[k][k]\n",
    "        \n",
    "\n",
    "    return q,r\n",
    "\n",
    "q,r = modified_gram(A)\n",
    "print(q)\n",
    "print(r)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eab4b6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.99569753, 0.05373748, 0.07548982]), array([-0.05788115,  0.99687179,  0.05381834]), array([-0.0723616 , -0.05795623,  0.99569316])]\n",
      "[[1.         0.38856772 0.55150358]\n",
      " [0.         1.         0.34475917]\n",
      " [0.         0.         1.        ]]\n",
      "[[3.96363727 0.21391626 0.30050717]\n",
      " [0.21391626 3.00006374 0.19017074]\n",
      " [0.30050717 0.19017074 3.20665818]]\n",
      "[0.21391626 3.00006374 0.19017074]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 3\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n",
    "\n",
    "def modified_gram_schmidt(vectors):\n",
    "    # Obtain the number of vectors\n",
    "    n = len(vectors)\n",
    "\n",
    "    # Initialize the list of orthonormal basis vectors and the r_matrix with zeros\n",
    "    orthonormal_basis = []\n",
    "    r_matrix = np.zeros((n, n))\n",
    "\n",
    "    # Iterate over the vectors\n",
    "    for i in range(n):\n",
    "        # Set the current vector to be the i-th vector\n",
    "        v = vectors[i]\n",
    "\n",
    "        # Subtract the projection of v onto the subspace spanned by the previous vectors\n",
    "        for j in range(i):\n",
    "            r = orthonormal_basis[j] @ v\n",
    "            v = v - r * orthonormal_basis[j]\n",
    "            r_matrix[j][i] = r\n",
    "\n",
    "        # Normalize v and add it to the list of orthonormal basis vectors\n",
    "        v = v / np.linalg.norm(v)\n",
    "        orthonormal_basis.append(v)\n",
    "        r_matrix[i][i] = np.linalg.norm(v)\n",
    "\n",
    "    # Return the orthonormal basis and the r_matrix\n",
    "    return orthonormal_basis, r_matrix\n",
    "\n",
    "q,r = modified_gram_schmidt(A)\n",
    "print(q)\n",
    "print(r)\n",
    "print(A)\n",
    "print(A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47b461",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Version Householder\n",
    "\n",
    "L'intérêt de la méthode de Householder est de faire intervenir des\n",
    "transformations unitaires dont on a vu qu'elles ne dégradaient pas le\n",
    "conditionnement $\\kappa_2$. Elle est donc réputée beaucoup plus stable\n",
    "qu'une technique de Gauss pour résoudre un système mais elle fait\n",
    "intervenir environ deux fois plus d'opérations. La méthode repose sur\n",
    "l'emploi des matrices de réflexion dites de Householder.\n",
    "\n",
    "On appelle matrice de réflexion de Householder la matrice $n\\times n$\n",
    "${\\mathbf{H}}$ :\n",
    "$${\\mathbf{H}}_{{\\mathbf{v}}} = {\\mathbf{I}}-2\\frac{{\\mathbf{v}}{\\mathbf{v}}^H}{{\\mathbf{v}}^H{\\mathbf{v}}}$$\n",
    "${\\mathbf{v}}$ est le vecteur de Householder.\n",
    "${\\mathbf{P}}$ est unitaire et hermitienne, elle réalise une\n",
    "réflexion par rapport à l'hyperplan\n",
    "${\\operatorname{vect}}({\\mathbf{v}})^\\perp$. Cette\n",
    "matrice est obtenue à partir de l'identité à l'aide d'une perturbation\n",
    "de rang 1.\n",
    "\n",
    "Le théorème utile est le suivant : Soit ${\\mathbf{a}}$ un\n",
    "vecteur de ${\\mathbb{C}}^n$ tel que $a_1\\neq 0$ et\n",
    "$\\sum_{i=2}^n|a_i|>0$. Il existe deux matrices de Householder\n",
    "${\\mathbf{H}}$ telles que les $(n-1)$ dernières composantes\n",
    "du vecteur ${\\mathbf{H}}{\\mathbf{a}}$ soit nulles.\n",
    "De façon plus précise, soit $\\alpha\\in {\\mathbb{R}}$ tel que\n",
    "$a_1 = e^{i\\alpha}|a_1|$, alors si ${\\mathbf{e}}_1$ est le\n",
    "premier vecteur de base de ${\\mathbb{C}}^n$:\n",
    "$${\\mathbf{H}}_{({\\mathbf{a}}+\\|{\\mathbf{a}}\\|_2 e^{i\\alpha} {\\mathbf{e}}_1)} {\\mathbf{a}} =- \\|{\\mathbf{a}}\\|_2 {\\mathbf{e}}_1,\\qquad {\\mathbf{H}}_{({\\mathbf{a}}-\\|{\\mathbf{a}}\\|_2 e^{i\\alpha} {\\mathbf{e}}_1)} {\\mathbf{a}} = \\|{\\mathbf{a}}\\|_2 {\\mathbf{e}}_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ef5a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En pratique, on calcule $\\|{\\mathbf{a}}\\|_2$ puis\n",
    "${\\mathbf{v}}=({\\mathbf{a}} \\pm \\|{\\mathbf{a}}\\|_2 e^{i\\alpha} {\\mathbf{e}}_1)$\n",
    "et le nombre\n",
    "$\\frac{{\\mathbf{v}}^H{\\mathbf{v}}}{2}=\\|{\\mathbf{a}}\\|_2(\\|{\\mathbf{a}}\\|_2\\pm |a_1|)$.\n",
    "Le calcul de l'image d'un vecteur ${\\mathbf{x}}$ se fait de\n",
    "la façon suivante :\n",
    "$${\\mathbf{H}}_v{\\mathbf{x}} = {\\mathbf{x}}-\\frac{{\\mathbf{v}}^H{\\mathbf{x}}}{{\\mathbf{v}}^H{\\mathbf{v}}/2}{\\mathbf{v}}$$\n",
    "Dans le cas réel le *signe est choisi* de manière à éviter un\n",
    "dénominateur trop petit donc on prend\n",
    "${\\mathbf{v}}=({\\mathbf{a}} +{\\operatorname{signe}}(a_1) \\|{\\mathbf{a}}\\|_2 {\\mathbf{e}}_1)$.\n",
    "\n",
    "La méthode de Householder consiste donc à calculer\n",
    "${\\mathbf{A}}_k={\\mathbf{H}}_{k-1}\\cdots{\\mathbf{H}}_1{\\mathbf{A}}$\n",
    "avec : $${\\mathbf{A}}_k = \n",
    "\\begin{pmatrix}\n",
    "\\times & \\times & \\times & \\times & \\times & \\times    \\\\\n",
    "& \\times & \\times & \\times & \\times & \\times  \\\\\n",
    "&        & \\times_{kk} & \\times & \\times & \\times  \\\\\n",
    "&        & \\times & \\times & \\times & \\times  \\\\\n",
    "&        & \\times & \\times & \\times & \\times  \\\\\n",
    "&        & \\times_{nk} & \\times & \\times & \\times  \\\\\n",
    "\\end{pmatrix}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6fb7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si besoin on pratique une permutation de lignes\n",
    "(permutation à droite) de manière à rendre le coefficient $kk$ non-nul.\n",
    "On extrait de ${\\mathbf{A}}_k$ le vecteur\n",
    "$\\tilde{{\\mathbf{a}}}_k$ de dimension $(n-k+1)$ de\n",
    "coefficients $a_{ik}$ $(k\\leqslant i \\leqslant n)$. On choisit le\n",
    "vecteur $\\tilde{{\\mathbf{v}}}_k$ tel que\n",
    "${\\mathbf{H}}_{\\tilde{{\\mathbf{v}}}_k}{\\mathbf{v}}_k$\n",
    "ait toutes ses composantes nulles sauf la première et on pose :\n",
    "$${\\mathbf{H}}_k = \n",
    "\\begin{pmatrix}\n",
    "{\\mathbf{I}}_{k-1} & {\\mathbf{0}} \\\\ {\\mathbf{0}} & {\\mathbf{H}}_{\\tilde{{\\mathbf{v}}}_k}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Il est possible de représenter le produit de $r$ matrices de Householder\n",
    "sous forme bloc :\n",
    "$${\\mathbf{Q}}={\\mathbf{I}}+{\\mathbf{W}}{\\mathbf{Y}}^H$$\n",
    "où ${\\mathbf{W}}$ et ${\\mathbf{Y}}$ sont des\n",
    "matrices $n\\times r$. Le mécanisme est le suivant :\n",
    "$${\\mathbf{Q}}{\\mathbf{H}}_{{\\mathbf{v}}}={\\mathbf{I}}+\\begin{pmatrix}{\\mathbf{W}},& -\\frac{2}{{\\mathbf{v}}^H{\\mathbf{v}}}{\\mathbf{Q}}{\\mathbf{v}}\\end{pmatrix}\\begin{pmatrix}{\\mathbf{Y}},& {\\mathbf{v}}\\end{pmatrix}^H$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e136ae3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Version Givens\n",
    "\n",
    "A l'instar de Householder, l'orthogonalisation de Givens fait intervenir\n",
    "des transformations unitaires et donc ne détériore pas le\n",
    "conditionnement $\\kappa_2$. La méthode repose sur l'emploi des matrices\n",
    "de rotations dites de Givens qui sont des perturbations de rang 2 de\n",
    "l'identité. Ces matrices permettent d'intervenir plus spécifiquement sur\n",
    "certains coefficients d'une matrice. Par simplicité, on se place dans\n",
    "${\\mathbb{R}}$. On pose :\n",
    "$${\\mathbf{G}}_{ij}(\\theta)=\\begin{pmatrix}\n",
    "{\\mathbf{I}}_{i-1} &             &    &   &{\\mathbf{0}} \\\\\n",
    "& \\cos(\\theta)_{ii}   &     {\\mathbf{0}}        &  \\sin(\\theta)_{ij} &    \\\\\n",
    "&  {\\mathbf{0}}   & {\\mathbf{I}}_{n-2} &  {\\mathbf{0}}  &    \\\\\n",
    "& -\\sin(\\theta)_{ji}  &      {\\mathbf{0}}       & \\cos(\\theta)_{jj}  &    \\\\\n",
    "{\\mathbf{0}}     &     &             &    & {\\mathbf{I}}_{n-j} \\\\ \n",
    "\\end{pmatrix}$$ Si on calcule le produit suivant :\n",
    "$${\\mathbf{Y}}={\\mathbf{G}}_{ik}(\\theta)^T {\\mathbf{X}} ;\\qquad y_{qr} = \\left\\{\n",
    "\\begin{array}{lr} \n",
    "\\cos(\\theta)x_{ir}-\\sin(\\theta)x_{jr} & q=i,\\ \\forall r \\\\\n",
    "\\sin(\\theta)x_{ir}+\\cos(\\theta)x_{jr} & q=j,\\ \\forall r \\\\\n",
    "x_{qr} & q\\neq i,j,\\ \\forall r  \\\\\n",
    "\\end{array}\\right.$$ L'idée derrière cela est de calculer $\\theta$ pour\n",
    "annuler des coefficients. Par exemple si on veut annuler $y_{qr}$ (ici\n",
    "les deux indices sont fixés), on prend $i$ tel que $x_{ir}\\neq 0$ et on\n",
    "pose\n",
    "$$\\cos(\\theta) = \\frac{x_{ir}}{\\sqrt{x_{ir}^2+x_{qr}^2}}, \\qquad \\sin(\\theta) = \\frac{x_{qr}}{\\sqrt{x_{ir}^2+x_{qr}^2}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53051569",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si on cherche à minimiser les erreurs d'arrondi, alors si $a$ et $b$ sont donnés et que\n",
    "l'on cherche $c=\\cos(\\theta)$ et $s=\\sin(\\theta)$ tels que\n",
    "$$\\begin{pmatrix}\n",
    "c & s \\\\ -s & c\n",
    "\\end{pmatrix}^T \\begin{pmatrix} a \\\\b \\end{pmatrix} = \\begin{pmatrix} r \\\\ 0 \\end{pmatrix}$$\n",
    "alors $$\\begin{array}{ll}\n",
    "\\text{si }b=0, & c=1,\\ s=0 \\\\\n",
    "\\text{si }|b|>|a|, & \\tau=-a/b,\\ s=1/\\sqrt{1+\\tau^2},\\ c=s\\tau \\\\\n",
    "\\text{si }|b|\\leqslant|a|, & \\tau=-b/a,\\ c=1/\\sqrt{1+\\tau^2},\\ c=c\\tau \n",
    "\\end{array}$$\n",
    "\n",
    "Une utilisation typique des rotations de Givens (le tilde indique une\n",
    "modification du coefficient d'une étape à l'autre) : $$\\begin{pmatrix}\n",
    "\\times & \\times & \\times \\\\\n",
    "\\times & \\times & \\times \\\\\n",
    "\\times & \\times & \\times \n",
    "\\end{pmatrix} \\xrightarrow{(3,1)} \n",
    "\\begin{pmatrix}\n",
    "\\times & \\times & \\times \\\\\n",
    "\\tilde{\\times} & \\tilde{\\times} & \\tilde{\\times} \\\\\n",
    "0      & \\tilde{\\times} & \\tilde{\\times} \n",
    "\\end{pmatrix} \\xrightarrow{(2,1)}\n",
    "\\begin{pmatrix}\n",
    "\\tilde{\\times} & \\tilde{\\times} & \\tilde{\\times} \\\\\n",
    "0 & \\tilde{\\times} & \\tilde{\\times} \\\\\n",
    "0      & \\times & \\times\n",
    "\\end{pmatrix}\\xrightarrow{(3,2)}\n",
    "\\begin{pmatrix}\n",
    "\\times & \\times & \\times \\\\\n",
    "0 & \\tilde{\\times} & \\tilde{\\times} \\\\\n",
    "0      & 0 & \\tilde{\\times}\n",
    "\\end{pmatrix}$$ On verra une application typique dans le solveur GMRes\n",
    "pour résoudre un système de Hessemberg.\n",
    "\n",
    "On propose de coder la détermination de la décomposition QR : on comparera $\\|{\\mathbf{Q}}^T{\\mathbf{Q}}-{\\mathbf{I}}\\|$ pour les version Gram-Schmidt et Givens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ac10ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from math import hypot\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "n = 200\n",
    "# A est une matrice symétrique, définie et positive\n",
    "A = np.random.random((n, n))\n",
    "A=A*A.transpose()+n*np.identity(n)\n",
    "\n",
    "def condit(M,i):\n",
    "    return la.norm(M,i)*la.norm(la.inv(M),i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9cb81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Factorisation QR et systèmes rectangulaires\n",
    "\n",
    "Les factorisation QR se prêtent bien au calcul de systèmes\n",
    "rectangulaires car la préservation de la norme permet de facilement\n",
    "intégrer les régularisations présentées précédemment.\n",
    "\n",
    "Si on considère un système sur déterminé\n",
    "${\\mathbf{A}}{\\mathbf{x}}={\\mathbf{b}}$\n",
    "avec ${\\mathbf{A}}\\in{\\mathbb{E}}^{m\\times n}$ et\n",
    "$m>n$. On a : $$\\begin{aligned}\n",
    "\\left\\| {\\mathbf{b}}-{\\mathbf{A}}{\\mathbf{x}}\\right\\|_2^2 & = \\left\\| {\\mathbf{b}}-\\begin{pmatrix}\n",
    "{\\mathbf{Q}}_1 & {\\mathbf{Q_2}} \n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "{\\mathbf{R}}_1 \\\\ 0 \n",
    "\\end{pmatrix} \\right\\|_2^2 \\\\\n",
    "&= \\left\\|\\begin{pmatrix}\n",
    "{\\mathbf{Q}}_1^H {\\mathbf{b}} - {\\mathbf{R}}_1 {\\mathbf{x}} \\\\ {\\mathbf{Q}}_2^H {\\mathbf{b}} \n",
    "\\end{pmatrix}\\right\\|_2^2 =  \\left\\|{\\mathbf{Q}}_1^H {\\mathbf{b}} - {\\mathbf{R}}_1 {\\mathbf{x}}\\right\\|_2^2 +\\left\\|{\\mathbf{Q}}_2^H {\\mathbf{b}}\\right\\|_2^2 \n",
    "\\end{aligned}$$ où l'on voit que le minimum est égal à\n",
    "$\\left\\|{\\mathbf{Q}}_2^H {\\mathbf{b}}\\right\\|_2^2$\n",
    "(qui mesure l'écart du second membre à l'image de\n",
    "${\\mathbf{A}}$) et est atteint pour\n",
    "${\\mathbf{R}}_1 {\\mathbf{x}} = {\\mathbf{Q}}_1^H {\\mathbf{b}}$\n",
    "(petit système triangulaire).\n",
    "\n",
    "Concernant les systèmes sous-déterminés $m<n$, on peut utiliser la\n",
    "factortisation $QR$ de ${\\mathbf{A}}^T$. On a :\n",
    "$$\\begin{aligned}\n",
    "{\\mathbf{A}}{\\mathbf{x}} & = {\\mathbf{b}}\\\\\n",
    "{\\mathbf{R^T}}{\\mathbf{Q}}^T{\\mathbf{x}}&={\\mathbf{b}}\n",
    "\\end{aligned}$$ Si on cherche ${\\mathbf{x}}$ sous la forme\n",
    "${\\mathbf{Q}}{\\mathbf{y}}+{\\mathbf{z}}$\n",
    "avec ${\\mathbf{Q}}^T{\\mathbf{z}}=0$, on a\n",
    "$\\|{\\mathbf{x}}\\|^2_2 = \\|{\\mathbf{y}}\\|^2_2 + \\|{\\mathbf{z}}\\|^2_2$.\n",
    "Donc\n",
    "${\\mathbf{x}}={\\mathbf{Q}}{\\mathbf{R}}^{-T}{\\mathbf{b}}$\n",
    "est la solution de norme minimale.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
